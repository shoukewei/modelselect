{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd2ff8f3-9a93-45ff-9f39-11f6951aa0d4",
   "metadata": {},
   "source": [
    "<h1 style='text-align: center;'>How to Use Python Modelselect Package</h1>\n",
    "<h3 style='text-align: center;'>Shouke Wei, Ph.D. Professor<sup>1,2</sup></h3>\n",
    "<h5 style='text-align: center;'><sup>1</sup> Deepsim Intelligence Technology Inc, BC V2T0G9, Abbotsford, Canada</h5>\n",
    "<h5 style='text-align: center;'><sup>2</sup> Deepsim Academy, BC V2T0G9, Abbotsford, Canada</h5>\n",
    "<h5 style='text-align: center;'>Email: shouke.wei@gmail.com</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a27ebc7-8c9c-4890-b3c4-72013739ca57",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b01cb154-72a0-4b71-ab07-dc3dca37559b",
   "metadata": {},
   "source": [
    "This is brief guide to display how to use Python `modelselect` Package rather than developing a linear regression model. Thus, the process does not strictly follow the modelling processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bc7f33-34c4-4ba6-b76c-b99bd93563b8",
   "metadata": {},
   "source": [
    "## 1. Brief Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea7f4f6-a8e3-4195-86b4-da71de3b2b36",
   "metadata": {},
   "source": [
    "### (1) What is `modelselect`?\n",
    "A package helps easily create an optimal linear regression model by removing the insignificant and multicollinearity predictor variables, which can help you reduce the interactive process and tedious work to run the model, estimate it, evaluate it, reestimate and reevaluate it, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df5e7b8-21fc-4fe6-b6b4-239122dee9e9",
   "metadata": {},
   "source": [
    "### (2) Install the Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65d6d8e-254c-482a-a4a5-5590473694d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install modelselect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fa81c4-2f3e-4f4c-b61b-30543c289882",
   "metadata": {},
   "source": [
    "### (3) Import the Package\n",
    "```python\n",
    "from modelselect import LRSelector\n",
    "```\n",
    "then use the `LRSelector()` directly. Or \n",
    "```python\n",
    "import modelselect as ms\n",
    "```\n",
    "then use `ms.LRSelector()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d1b003-ad3d-4888-bd9f-0ffd106331de",
   "metadata": {},
   "source": [
    "### (4) Methods \n",
    "There are three paremeters in the functioms.\n",
    "`modelselect.LRSelector(X, y, X_drop)`\n",
    "\n",
    "**Paremeters**:\n",
    "- X: feature variables, normalized or original\n",
    "- y: target variables\n",
    "- X_drop: a list contains the names of the variables to be removed. The default is empty, i.e. no drop variables\n",
    "\n",
    "**Returns**:\n",
    "- res: OLS estimation results\n",
    "- vif: Variance Inflation Factor\n",
    "- X_new: feature variables after removing variables. When X_drop is default, X_new is equal to X.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3177f796-2c05-43b8-9ec1-283d1399261a",
   "metadata": {},
   "source": [
    "## 2. Use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6516e2-bede-4c90-b64c-6474fe79eff1",
   "metadata": {},
   "source": [
    "### (1) Import required packages\n",
    "Besides this package, we also required `numpy`,`Pandas`,`statsmodels`, `normsscaler` and `scikit-learn`. Maybe you are familiar with `Pandas`, `scikit-learn`, but you probably donot know `normscaler`. You can find the [`normscaler` package] (https://pypi.org/project/normscaler/) on PyPi and [one post article](https://medium.com/@shouke.wei/a-handy-data-normalization-package-in-python-3b863b829eaa) on Medium. \n",
    "\n",
    "You can install them using `pip` as follows if you have installed them.\n",
    "\n",
    "```Python\n",
    "pip install pandas, scikit-learn, normscaler\n",
    "```\n",
    "Now, let's import them as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "224f9a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tools.eval_measures import meanabs,mse,rmse\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import modelselect as ms\n",
    "from normscaler.scaler import DecimalScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8786ec8b-067b-41f5-bbc0-2d3f63352ac1",
   "metadata": {},
   "source": [
    "### (2) Read data to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e181cab-bc29-488e-b2a6-3a38ef4f9c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>gdp</th>\n",
       "      <th>pop</th>\n",
       "      <th>finv</th>\n",
       "      <th>trade</th>\n",
       "      <th>fexpen</th>\n",
       "      <th>uinc</th>\n",
       "      <th>prov_gd</th>\n",
       "      <th>prov_hn</th>\n",
       "      <th>prov_js</th>\n",
       "      <th>prov_sd</th>\n",
       "      <th>prov_zj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>1.074125</td>\n",
       "      <td>8.650000</td>\n",
       "      <td>0.314513</td>\n",
       "      <td>1.408147</td>\n",
       "      <td>0.108032</td>\n",
       "      <td>0.976157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>1.203925</td>\n",
       "      <td>8.733000</td>\n",
       "      <td>0.348443</td>\n",
       "      <td>1.501391</td>\n",
       "      <td>0.132133</td>\n",
       "      <td>1.041519</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>1.350242</td>\n",
       "      <td>8.842000</td>\n",
       "      <td>0.385078</td>\n",
       "      <td>1.830169</td>\n",
       "      <td>0.152108</td>\n",
       "      <td>1.113720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>1.584464</td>\n",
       "      <td>8.963000</td>\n",
       "      <td>0.481320</td>\n",
       "      <td>2.346735</td>\n",
       "      <td>0.169563</td>\n",
       "      <td>1.238043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>1.886462</td>\n",
       "      <td>9.052298</td>\n",
       "      <td>0.587002</td>\n",
       "      <td>2.955899</td>\n",
       "      <td>0.185295</td>\n",
       "      <td>1.362765</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       gdp       pop      finv     trade    fexpen      uinc  prov_gd  \\\n",
       "0  2000  1.074125  8.650000  0.314513  1.408147  0.108032  0.976157      1.0   \n",
       "1  2001  1.203925  8.733000  0.348443  1.501391  0.132133  1.041519      1.0   \n",
       "2  2002  1.350242  8.842000  0.385078  1.830169  0.152108  1.113720      1.0   \n",
       "3  2003  1.584464  8.963000  0.481320  2.346735  0.169563  1.238043      1.0   \n",
       "4  2004  1.886462  9.052298  0.587002  2.955899  0.185295  1.362765      1.0   \n",
       "\n",
       "   prov_hn  prov_js  prov_sd  prov_zj  \n",
       "0      0.0      0.0      0.0      0.0  \n",
       "1      0.0      0.0      0.0      0.0  \n",
       "2      0.0      0.0      0.0      0.0  \n",
       "3      0.0      0.0      0.0      0.0  \n",
       "4      0.0      0.0      0.0      0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/shoukewei/data/main/data-pydm/gdp_china_encoded.csv'\n",
    "df = pd.read_csv(url,index_col=False)\n",
    "\n",
    "# display the first rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3a6d16-77c5-4756-859d-85189ae62675",
   "metadata": {},
   "source": [
    "### (3)  Define independent variables (X) and dependent variable (y)\n",
    "GDP is the target and others are features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36d6af09-86df-43e4-8222-93a58acacbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['gdp'],axis=1)\n",
    "y = df['gdp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4e6ccd-f5c0-4460-88d9-36b8e00b5c96",
   "metadata": {},
   "source": [
    "### (4) Split dataset for model training and testing\n",
    "Split the dataset for model training/estimation and testing/validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e2e63a1-8358-4322-9025-d1b66ef3ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf91169-3c55-4778-a859-105f9eb5a8d1",
   "metadata": {},
   "source": [
    "### (5) Normalize datasets with with decimal scaling method\n",
    "We use the `DecimalScaler` (Decimal scaling method) in `normscaler` package to normalize the X_train and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54009f9e-06e8-43fa-bc85-8230e2004a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled = DecimalScaler(X_train,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e9a34e-3392-42fc-86c5-b6456c6ba94b",
   "metadata": {},
   "source": [
    "### (6) Create a linear regression model using `modelselector` package \n",
    "First, we will use all the feature variables, i.e there is drop, or X_drop is the default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c27926e9-c176-416f-a48c-e120ff9968ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shouk\\anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1736: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "C:\\Users\\shouk\\anaconda3\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:195: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    }
   ],
   "source": [
    "modelres = ms.LRSelector(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4fe457-86fe-46e7-ab66-8ffae4f9ceb1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (7) Display the results\n",
    "#### (i) display the OLS regression results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0785df6f-3a4b-48c1-a1bb-02fc1a7de9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>gdp</td>       <th>  R-squared:         </th> <td>   0.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.990</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   655.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 23 Dec 2022</td> <th>  Prob (F-statistic):</th> <td>2.10e-53</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:39:27</td>     <th>  Log-Likelihood:    </th> <td>  4.6076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    66</td>      <th>  AIC:               </th> <td>   12.78</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    55</td>      <th>  BIC:               </th> <td>   36.87</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>  156.8809</td> <td>   51.944</td> <td>    3.020</td> <td> 0.004</td> <td>   52.783</td> <td>  260.979</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>year</th>    <td>   -0.0938</td> <td>    0.031</td> <td>   -3.000</td> <td> 0.004</td> <td>   -0.157</td> <td>   -0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop</th>     <td>   -0.0581</td> <td>    0.118</td> <td>   -0.493</td> <td> 0.624</td> <td>   -0.294</td> <td>    0.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>finv</th>    <td>    0.6182</td> <td>    0.088</td> <td>    7.042</td> <td> 0.000</td> <td>    0.442</td> <td>    0.794</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>trade</th>   <td>    0.5580</td> <td>    0.072</td> <td>    7.701</td> <td> 0.000</td> <td>    0.413</td> <td>    0.703</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fexpen</th>  <td>    2.3306</td> <td>    0.330</td> <td>    7.064</td> <td> 0.000</td> <td>    1.669</td> <td>    2.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>uinc</th>    <td>    0.4059</td> <td>    0.128</td> <td>    3.165</td> <td> 0.003</td> <td>    0.149</td> <td>    0.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prov_gd</th> <td>   30.7057</td> <td>   10.309</td> <td>    2.979</td> <td> 0.004</td> <td>   10.047</td> <td>   51.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prov_hn</th> <td>   31.7368</td> <td>   10.432</td> <td>    3.042</td> <td> 0.004</td> <td>   10.831</td> <td>   52.643</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prov_js</th> <td>   31.2903</td> <td>   10.378</td> <td>    3.015</td> <td> 0.004</td> <td>   10.491</td> <td>   52.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prov_sd</th> <td>   32.1263</td> <td>   10.377</td> <td>    3.096</td> <td> 0.003</td> <td>   11.329</td> <td>   52.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prov_zj</th> <td>   31.0217</td> <td>   10.459</td> <td>    2.966</td> <td> 0.004</td> <td>   10.061</td> <td>   51.983</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.168</td> <th>  Durbin-Watson:     </th> <td>   1.879</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.920</td> <th>  Jarque-Bera (JB):  </th> <td>   0.360</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.053</td> <th>  Prob(JB):          </th> <td>   0.835</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.654</td> <th>  Cond. No.          </th> <td>1.30e+19</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.57e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    gdp   R-squared:                       0.992\n",
       "Model:                            OLS   Adj. R-squared:                  0.990\n",
       "Method:                 Least Squares   F-statistic:                     655.2\n",
       "Date:                Fri, 23 Dec 2022   Prob (F-statistic):           2.10e-53\n",
       "Time:                        20:39:27   Log-Likelihood:                 4.6076\n",
       "No. Observations:                  66   AIC:                             12.78\n",
       "Df Residuals:                      55   BIC:                             36.87\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        156.8809     51.944      3.020      0.004      52.783     260.979\n",
       "year          -0.0938      0.031     -3.000      0.004      -0.157      -0.031\n",
       "pop           -0.0581      0.118     -0.493      0.624      -0.294       0.178\n",
       "finv           0.6182      0.088      7.042      0.000       0.442       0.794\n",
       "trade          0.5580      0.072      7.701      0.000       0.413       0.703\n",
       "fexpen         2.3306      0.330      7.064      0.000       1.669       2.992\n",
       "uinc           0.4059      0.128      3.165      0.003       0.149       0.663\n",
       "prov_gd       30.7057     10.309      2.979      0.004      10.047      51.365\n",
       "prov_hn       31.7368     10.432      3.042      0.004      10.831      52.643\n",
       "prov_js       31.2903     10.378      3.015      0.004      10.491      52.089\n",
       "prov_sd       32.1263     10.377      3.096      0.003      11.329      52.923\n",
       "prov_zj       31.0217     10.459      2.966      0.004      10.061      51.983\n",
       "==============================================================================\n",
       "Omnibus:                        0.168   Durbin-Watson:                   1.879\n",
       "Prob(Omnibus):                  0.920   Jarque-Bera (JB):                0.360\n",
       "Skew:                          -0.053   Prob(JB):                        0.835\n",
       "Kurtosis:                       2.654   Cond. No.                     1.30e+19\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.57e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = modelres[0]\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69189a8b-949d-40da-96c0-db4f32af9101",
   "metadata": {},
   "source": [
    "From the above results, we know the modle is good, but *pop* is statistically insignificant at the level of 0.05. There might be strong multicollinearity problems due to the smallest eigenvalue of 1.57e-30.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8a52a1-e222-4538-b651-e2db47ead853",
   "metadata": {},
   "source": [
    "#### (ii) display the VIF\n",
    "It further confirms that there are strong multicollinearity problems due to the larger VIF. It widely accepts that a VIF > 10 as an indicator of multicollinearity, but some scholars choose a more conservative threshold of 5 or even 2.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48b10f3c-e217-47d9-b8b0-5bb794186989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>const</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.6</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.7</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.4</td>\n",
       "      <td>finv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.8</td>\n",
       "      <td>trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.9</td>\n",
       "      <td>fexpen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25.9</td>\n",
       "      <td>uinc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>inf</td>\n",
       "      <td>prov_gd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>inf</td>\n",
       "      <td>prov_hn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>inf</td>\n",
       "      <td>prov_js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>inf</td>\n",
       "      <td>prov_sd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>inf</td>\n",
       "      <td>prov_zj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    VIF Factor features\n",
       "0          0.0    const\n",
       "1         30.6     year\n",
       "2         51.7      pop\n",
       "3         19.4     finv\n",
       "4         23.8    trade\n",
       "5         17.9   fexpen\n",
       "6         25.9     uinc\n",
       "7          inf  prov_gd\n",
       "8          inf  prov_hn\n",
       "9          inf  prov_js\n",
       "10         inf  prov_sd\n",
       "11         inf  prov_zj"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif = modelres[1]\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1563c5a4-a798-4a78-815e-6def8834ed2c",
   "metadata": {},
   "source": [
    "### (8) Improve the model\n",
    "First, let's remove the insignificant variable, pop, and run the model to estimate the model again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68dd2272-361d-4303-82ff-1629de1ac0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shouk\\anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1736: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "C:\\Users\\shouk\\anaconda3\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:195: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    }
   ],
   "source": [
    "X_drop=['pop']\n",
    "res_drop_pop, vif_drop_pop,X_drop_pop = ms.LRSelector(X_train, y_train,X_drop=X_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "030d9813-d5e1-4c84-b3e6-75e62b909d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    gdp   R-squared:                       0.992\n",
      "Model:                            OLS   Adj. R-squared:                  0.990\n",
      "Method:                 Least Squares   F-statistic:                     738.0\n",
      "Date:                Fri, 23 Dec 2022   Prob (F-statistic):           8.45e-55\n",
      "Time:                        20:39:27   Log-Likelihood:                 4.4622\n",
      "No. Observations:                  66   AIC:                             11.08\n",
      "Df Residuals:                      56   BIC:                             32.97\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        162.7680     50.209      3.242      0.002      62.188     263.348\n",
      "year          -0.0976      0.030     -3.239      0.002      -0.158      -0.037\n",
      "finv           0.6218      0.087      7.156      0.000       0.448       0.796\n",
      "trade          0.5386      0.060      8.918      0.000       0.418       0.660\n",
      "fexpen         2.3460      0.326      7.191      0.000       1.692       2.999\n",
      "uinc           0.4189      0.125      3.360      0.001       0.169       0.669\n",
      "prov_gd       31.8464      9.977      3.192      0.002      11.860      51.833\n",
      "prov_hn       32.8207     10.128      3.240      0.002      12.531      53.110\n",
      "prov_js       32.5113     10.010      3.248      0.002      12.459      52.564\n",
      "prov_sd       33.2214     10.068      3.300      0.002      13.053      53.390\n",
      "prov_zj       32.3683     10.028      3.228      0.002      12.280      52.456\n",
      "==============================================================================\n",
      "Omnibus:                        0.039   Durbin-Watson:                   1.884\n",
      "Prob(Omnibus):                  0.981   Jarque-Bera (JB):                0.208\n",
      "Skew:                          -0.020   Prob(JB):                        0.901\n",
      "Kurtosis:                       2.728   Cond. No.                     1.22e+19\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.8e-30. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "    VIF Factor features\n",
      "0          0.0    const\n",
      "1         28.8     year\n",
      "2         19.3     finv\n",
      "3         16.7    trade\n",
      "4         17.7   fexpen\n",
      "5         24.9     uinc\n",
      "6          inf  prov_gd\n",
      "7          inf  prov_hn\n",
      "8          inf  prov_js\n",
      "9          inf  prov_sd\n",
      "10         inf  prov_zj\n"
     ]
    }
   ],
   "source": [
    "print(res_drop_pop.summary())\n",
    "print(vif_drop_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846ce51c-a2d8-4ab6-a7fb-6920502cd1e3",
   "metadata": {},
   "source": [
    "The results display that all the variables after dropping pop are all statistically significant at the level of 0.05. But VIF results shows that the model still has multicollieality. \n",
    "\n",
    "Thus, we need to further drop some variables which VIF is larger than the threshold. Let's start to drop prov_gd with inf VIF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0f0920a-97d6-4d91-a8a2-893ab516cd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    gdp   R-squared:                       0.992\n",
      "Model:                            OLS   Adj. R-squared:                  0.990\n",
      "Method:                 Least Squares   F-statistic:                     738.0\n",
      "Date:                Fri, 23 Dec 2022   Prob (F-statistic):           8.45e-55\n",
      "Time:                        20:39:27   Log-Likelihood:                 4.4622\n",
      "No. Observations:                  66   AIC:                             11.08\n",
      "Df Residuals:                      56   BIC:                             32.97\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        194.6144     60.185      3.234      0.002      74.049     315.180\n",
      "year          -0.0976      0.030     -3.239      0.002      -0.158      -0.037\n",
      "finv           0.6218      0.087      7.156      0.000       0.448       0.796\n",
      "trade          0.5386      0.060      8.918      0.000       0.418       0.660\n",
      "fexpen         2.3460      0.326      7.191      0.000       1.692       2.999\n",
      "uinc           0.4189      0.125      3.360      0.001       0.169       0.669\n",
      "prov_hn        0.9743      0.253      3.853      0.000       0.468       1.481\n",
      "prov_js        0.6649      0.139      4.775      0.000       0.386       0.944\n",
      "prov_sd        1.3750      0.208      6.604      0.000       0.958       1.792\n",
      "prov_zj        0.5219      0.203      2.566      0.013       0.114       0.929\n",
      "==============================================================================\n",
      "Omnibus:                        0.039   Durbin-Watson:                   1.884\n",
      "Prob(Omnibus):                  0.981   Jarque-Bera (JB):                0.208\n",
      "Skew:                          -0.020   Prob(JB):                        0.901\n",
      "Kurtosis:                       2.728   Cond. No.                     4.00e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large,  4e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "   VIF Factor features\n",
      "0   3966117.3    const\n",
      "1        28.8     year\n",
      "2        19.3     finv\n",
      "3        16.7    trade\n",
      "4        17.7   fexpen\n",
      "5        24.9     uinc\n",
      "6        10.4  prov_hn\n",
      "7         3.4  prov_js\n",
      "8         6.1  prov_sd\n",
      "9         7.6  prov_zj\n"
     ]
    }
   ],
   "source": [
    "X_drop=['pop','prov_gd']\n",
    "res_drop_gd, vif_drop_gd,X_drop_gd = ms.LRSelector(X_train, y_train,X_drop=X_drop)\n",
    "print(res_drop_gd.summary())\n",
    "print(vif_drop_gd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b30830-1d21-4fa9-b2fc-c19f7bc5fdbc",
   "metadata": {},
   "source": [
    "You can see the VIF of some variables are still larger, then we add the year to the drop list due to its larger VIF. We continue the process untill the all VIF are less than or equal to 10 except the constant. The final results looks as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74c7baca-256d-49da-82db-b8e212190e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    gdp   R-squared:                       0.980\n",
      "Model:                            OLS   Adj. R-squared:                  0.978\n",
      "Method:                 Least Squares   F-statistic:                     479.4\n",
      "Date:                Fri, 23 Dec 2022   Prob (F-statistic):           4.07e-48\n",
      "Time:                        20:39:27   Log-Likelihood:                -24.486\n",
      "No. Observations:                  66   AIC:                             62.97\n",
      "Df Residuals:                      59   BIC:                             78.30\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.7226      0.239     -3.025      0.004      -1.201      -0.245\n",
      "finv           1.0128      0.045     22.408      0.000       0.922       1.103\n",
      "trade          0.7652      0.056     13.646      0.000       0.653       0.877\n",
      "prov_hn        1.0056      0.290      3.474      0.001       0.426       1.585\n",
      "prov_js        0.5495      0.202      2.714      0.009       0.144       0.955\n",
      "prov_sd        1.2084      0.281      4.297      0.000       0.646       1.771\n",
      "prov_zj        0.8092      0.224      3.615      0.001       0.361       1.257\n",
      "==============================================================================\n",
      "Omnibus:                        3.064   Durbin-Watson:                   1.541\n",
      "Prob(Omnibus):                  0.216   Jarque-Bera (JB):                2.325\n",
      "Skew:                           0.275   Prob(JB):                        0.313\n",
      "Kurtosis:                       3.737   Cond. No.                         42.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "   VIF Factor features\n",
      "0        27.4    const\n",
      "1         2.3     finv\n",
      "2         6.3    trade\n",
      "3         6.0  prov_hn\n",
      "4         3.1  prov_js\n",
      "5         4.9  prov_sd\n",
      "6         4.0  prov_zj\n"
     ]
    }
   ],
   "source": [
    "X_drop=['pop','prov_gd','year','fexpen','uinc']\n",
    "res_drop_final, vif_drop_final,X_drop_final = ms.LRSelector(X_train, y_train,X_drop=X_drop)\n",
    "print(res_drop_final.summary())\n",
    "print(vif_drop_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d335641d-556d-4a49-aa01-bb9a046411ae",
   "metadata": {},
   "source": [
    "### (9) Model validation/testing\n",
    "Let's test the model using the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d45a4b8-2783-4400-a252-11bf6e9a2311",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_drop = X_test.drop(['pop','prov_gd','year','fexpen','uinc'],axis=1)\n",
    "\n",
    "X_test_drop = sm.add_constant(X_test_drop)\n",
    "\n",
    "y_pred = res_drop_final.predict(X_test_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7202ae-ab00-44df-aa2b-4e229c710eec",
   "metadata": {},
   "source": [
    "Then, we calculate MAE, MSE, RMSE and MAPE of the testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6c10438-6320-43fa-947e-68c7f6c18f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_absolute_error(MAE):  0.19150624526331034\n",
      "mean_squared_error(MSE):  0.05467623605841458\n",
      "root_mean_squared_error(RMSE):  0.23382950211300238\n",
      "mean_absolute_percentage_error(MAPE):  0.08418013652994877\n"
     ]
    }
   ],
   "source": [
    "print(\"mean_absolute_error(MAE): \", meanabs(y_test,y_pred))\n",
    "print(\"mean_squared_error(MSE): \", mse(y_test,y_pred))\n",
    "print(\"root_mean_squared_error(RMSE): \",rmse(y_test,y_pred))\n",
    "print (\"mean_absolute_percentage_error(MAPE): \",np.mean((abs(y_test-y_pred))/y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ad6f5f-512c-484f-b6b0-0f53f233c3ce",
   "metadata": {},
   "source": [
    "The testing results show that the model has very good prediction performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "e7e3b838abd1c700ae87169c06aaa45cda39826d3d76842d5152f8fefc86811d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
